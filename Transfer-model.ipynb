{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f010196-f566-4792-aab9-a3a9875aca35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Transfer model from Hugging Face to Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22e0b2e-4abc-4613-8f10-4b9997680c83",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554c844-11bd-423a-a95d-6735d15fc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install huggingface_hub boto3 botocore tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654d164-193e-458a-8237-71fdfa890b45",
   "metadata": {},
   "source": [
    "##  Transfer model from hugging face to object storage\n",
    "\n",
    "This script will copy the model set in `repo` from Hugging Face to the local Minio instance, specifically to the path set in `s3_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69be1ef-d6c7-4767-a11c-39c5e5cfe7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, argparse, pathlib\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login, snapshot_download\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "def upload_dir_to_s3(local_dir, bucket, prefix, s3):\n",
    "    local_dir = pathlib.Path(local_dir)\n",
    "    for p in local_dir.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            rel = p.relative_to(local_dir).as_posix()\n",
    "            key = f\"{prefix.rstrip('/')}/{rel}\"\n",
    "            s3.upload_file(str(p), bucket, key)\n",
    "            print(\"Upload complete: \", str(p))\n",
    "\n",
    "def main():\n",
    "    hf_token = os.environ.get('HF_TOKEN')\n",
    "    repo = \"RedHatAI/gemma-3-12b-it-quantized.w4a16\"\n",
    "                                        \n",
    "    s3_endpoint = os.environ.get('AWS_S3_ENDPOINT')\n",
    "    s3_region = os.environ.get('AWS_DEFAULT_REGION')\n",
    "    s3_access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "    s3_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "    s3_bucket = os.environ.get('AWS_S3_BUCKET')\n",
    "    s3_path = \"RedHatAI/gemma-3-12b-it-quantized.w4a16\"\n",
    "    insecure = \"true\"\n",
    "    \n",
    "    if hf_token:\n",
    "        login(hf_token)\n",
    "\n",
    "    print(f\"Downloading HF snapshot: {repo}\")\n",
    "    local_path = snapshot_download(repo)\n",
    "    print(\"Downloaded to:\", local_path)\n",
    "\n",
    "    session = boto3.session.Session(region_name=s3_region)\n",
    "    s3 = session.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=s3_access_key,\n",
    "        aws_secret_access_key=s3_secret_access_key,\n",
    "        endpoint_url=s3_endpoint or None,\n",
    "        config=Config(signature_version=\"s3v4\", s3={\"addressing_style\": \"path\"})\n",
    "    )\n",
    "\n",
    "    print(f\"Uploading to s3://{s3_bucket}/{s3_path.rstrip('/')}/ â€¦\")\n",
    "    upload_dir_to_s3(local_path, s3_bucket, s3_path, s3)\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f4849-eaf9-4f2c-9bf7-3115cb796f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "I "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
